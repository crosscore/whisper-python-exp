# app.py
import streamlit as st
import os
from datetime import datetime
from config import AUDIO_DIR, MODEL_DIR
from audio_recorder import AudioRecorder, save_audio, get_audio_duration
from transcription import load_whisper_model, transcribe_audio, save_transcription_to_file

MODEL_DIR.mkdir(exist_ok=True)
AUDIO_DIR.mkdir(exist_ok=True)

def initialize_whisper():
    """Whisperãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–"""
    if 'whisper_model' not in st.session_state:
        with st.spinner('Whisperãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...'):
            st.session_state.whisper_model = load_whisper_model()

def main():
    st.title("éŸ³å£°èªè­˜ãƒ»éŒ²éŸ³ã‚¢ãƒ—ãƒª")

    initialize_whisper()

    if 'audio_recorder' not in st.session_state:
        st.session_state.audio_recorder = AudioRecorder()

    # éŒ²éŸ³ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ç”¨ã®ã‚«ãƒ©ãƒ 
    col1, col2 = st.columns(2)

    with col1:
        if not st.session_state.audio_recorder.is_recording:
            if st.button("ğŸ¤ éŒ²éŸ³é–‹å§‹"):
                st.session_state.audio_recorder.start_recording()
                st.rerun()

    with col2:
        if st.session_state.audio_recorder.is_recording:
            if st.button("â¹ éŒ²éŸ³åœæ­¢"):
                recorded_audio = st.session_state.audio_recorder.stop_recording()
                if recorded_audio is not None:
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    filename = AUDIO_DIR / f"audio_{timestamp}.wav"
                    save_audio(recorded_audio, filename)
                    st.success(f"éŒ²éŸ³ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {filename}")
                st.rerun()

    if st.session_state.audio_recorder.is_recording:
        st.warning("éŒ²éŸ³ä¸­...")

    # éŒ²éŸ³æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸€è¦§è¡¨ç¤º
    st.subheader("éŒ²éŸ³æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«")
    audio_files = [f for f in os.listdir(AUDIO_DIR) if f.endswith('.wav')]

    # æ–‡å­—èµ·ã“ã—å‡¦ç†ã®çŠ¶æ…‹ã‚’ä¿æŒ
    if 'transcription_states' not in st.session_state:
        st.session_state.transcription_states = {}

    if audio_files:
        for audio_file in sorted(audio_files, reverse=True):
            file_path = AUDIO_DIR / audio_file
            txt_file_path = file_path.with_suffix(".txt")
            duration = get_audio_duration(file_path)

            # ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã®ã‚³ãƒ³ãƒ†ãƒŠã‚’ä½œæˆ
            with st.container():
                # 3åˆ—ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ: ã‚ªãƒ¼ãƒ‡ã‚£ã‚ª(4) | ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«(2) | æ–‡å­—èµ·ã“ã—çµæœ(6)
                col_audio, col_controls, col_text = st.columns([4, 2, 6])

                with col_audio:
                    st.markdown(f"##### {audio_file} ({duration}ç§’)")
                    with open(file_path, 'rb') as audio_file_open:
                        st.audio(audio_file_open.read(), format='audio/wav')

                with col_controls:
                    st.markdown("&nbsp;")  # ã‚¹ãƒšãƒ¼ã‚µãƒ¼
                    col_del, col_trans = st.columns(2)
                    with col_del:
                        if st.button("ğŸ—‘ï¸", key=f"delete_{audio_file}"):
                            os.remove(file_path)
                            if txt_file_path.exists():
                                os.remove(txt_file_path)
                            if audio_file in st.session_state.transcription_states:
                                del st.session_state.transcription_states[audio_file]
                            st.rerun()

                    with col_trans:
                        transcribe_button = st.button("ğŸ“", key=f"transcribe_{audio_file}")

                with col_text:
                    # æ–‡å­—èµ·ã“ã—çŠ¶æ…‹ã®ç®¡ç†ã¨è¡¨ç¤º
                    if transcribe_button:
                        st.session_state.transcription_states[audio_file] = "processing"
                        st.rerun()

                    if audio_file in st.session_state.transcription_states and st.session_state.transcription_states[audio_file] == "processing":
                        # æ–‡å­—èµ·ã“ã—å‡¦ç†ä¸­ã®è¡¨ç¤º
                        st.info("ğŸ”„ æ–‡å­—èµ·ã“ã—ä¸­...")
                        transcription = transcribe_audio(file_path, st.session_state.whisper_model)
                        if transcription:
                            save_transcription_to_file(file_path, transcription)
                            st.session_state.transcription_states[audio_file] = "completed"
                            st.rerun()
                        else:
                            st.session_state.transcription_states[audio_file] = "error"
                            st.error("âŒ æ–‡å­—èµ·ã“ã—ã«å¤±æ•—ã—ã¾ã—ãŸ")
                            st.rerun()
                    elif txt_file_path.exists():
                        # æ–‡å­—èµ·ã“ã—çµæœã®è¡¨ç¤º
                        with open(txt_file_path, 'r', encoding='utf-8') as f:
                            transcription = f.read()
                            st.text_area("", transcription, height=100, key=f"text_{audio_file}",
                                        label_visibility="collapsed")
                    else:
                        # æœªå‡¦ç†ã®çŠ¶æ…‹è¡¨ç¤º
                        st.text_area("", "ğŸ“ æ–‡å­—èµ·ã“ã—ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦å‡¦ç†ã‚’é–‹å§‹", height=100,
                                    key=f"placeholder_{audio_file}", label_visibility="collapsed",
                                    disabled=True)
    else:
        st.info("éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“")

if __name__ == "__main__":
    main()
